{"name":"Smart-filter","tagline":"This repository aims to create a mobile image segmentation model and incorporate background according to the human emotion","body":"# Smart-Filter\r\nThis repository aims to create a mobile image segmentation model and incorporate background according to the human emotion\r\n\r\nAim of this project is to create **end-to-end pipeline** from engineering machine learning model to deployement of the same. This is achieved using *Docker* and *Flask* as microservice to host the learned model on an EC2 instance. Seperate models are trained on [COCOdataset](https://cocodataset.org/) using detectron2 on pytorch and other datasets using *tensorflow-gpu==2.2.0.*\r\n\r\n## Overview\r\n\r\nSmart filter uses machine **learning to curate image specific filters and background**. There will be little to no input of user in deciding the final image.\r\nSmart filter is a useful tool to interact and share pictures across social media. 100s of thousands of images are uploaded every single minute. These picures take many forms such as stories, posts, comments, stickers and more.\r\n\r\nThere are 3 parts to this project:\r\n- Semantic Segmentation using [detectron2](https://github.com/facebookresearch/detectron2)\r\n- Face detection using transfer learning on *detectron2* itself.\r\n- Smile detection on detected face.\r\n\r\n## Pre-requisites\r\n1. pytorch\r\n2. cuda 10.1\r\n3. tensorflow\r\n4. torchvision\r\n5. numpy\r\n6. detectron2\r\n7. PIL\r\n\r\n## Examples\r\n\r\n### Background Removal\r\n\r\nThis API can be used to remove background and place either a fixed preset, or another aesthetically good looking background using parameters given by user.\r\n\r\n```python\r\npath = '/content/'\r\n#returns necessary attrbutes and results from model output\r\nim, human_masks, boxes = return_attributes(path+'me.jpg')\r\nprint('Masks calculated')\r\n\r\n# list of singular human images\r\nfinal_images = bound_human_boxes(boxes)\r\n\r\n# final mask => NxM bool matrix : value is 1 if human is present on the pixel\r\nfinal_mask = return_union_mask(im, human_masks)\r\nprint('Final Mask created')\r\n\r\n# Remove background and show the resultant image \r\ncv2_imshow(remove_bg(im, final_mask))\r\n```\r\n\r\nOriginal Image             |  Background removal using Semantic Segmentation\r\n:-------------------------:|:-------------------------:\r\n![](https://raw.githubusercontent.com/CRekkaran/Smart-Filter/master/Semantic%20Segmentation/person_selfie.jpg?token=AH47IOWYYRBYV67ISUQVXI27CQRI2)  |  ![](https://github.com/CRekkaran/Smart-Filter/blob/master/Semantic%20Segmentation/unsplashFilter.jpg)\r\n\r\n### Face detection using transfer learning on detectron2\r\n\r\nThis model is created using 510 images with 1600 instances on faces in the [dataset](https://www.kaggle.com/dataturks/face-detection-in-images)\r\nThus, the learning is not as rigorous as it could be. But I have achieved an **F1 score of 0.702** which was good enough.\r\n> Insert model quality metrics. Insert code snippet.\r\n\r\n\r\nImage 1             |  Image 2\r\n:-------------------------:|:-------------------------:\r\n![](https://github.com/CRekkaran/Smart-Filter/blob/master/Face%20detection%20using%20Detectron2/index.png)  |  ![](https://github.com/CRekkaran/Smart-Filter/blob/master/Face%20detection%20using%20Detectron2/index1.png)\r\n\r\nRight now, Face Filter is used primarily for selfies thus, the achived results are satisfactory.\r\n\r\n### Smile Detection\r\n\r\nSelfies taken are inherently full of features which can be used to automate creating appropriate face filters. For example, facial features can be used as a good way to describe a selfie. I have created only smile detection so far.  \r\nThe final model predicts on a given face. You can use either a haar frontal face cascade or another pretrained CNN model to localise the faces in image.\r\n> Insert model quality metrics.\r\n\r\n```python\r\nsmile_predictor = SmileModel('/content/drive/My Drive/Colab Notebooks/smiledetection.h5')\r\ntemp = cv2.resize(temp, dsize=(64, 64))\r\ntemp = temp.reshape(1, 64, 64, 3)\r\nprobability = smile_predictor.predict(temp)\r\n```\r\n\r\nImage 1             |  Image 2 | Image 3\r\n:-------------------------:|:-------------------------:|:-------------------------:\r\n![](https://github.com/CRekkaran/Smart-Filter/blob/master/Smile%20Detection/1.png)  |  ![](https://github.com/CRekkaran/Smart-Filter/blob/master/Smile%20Detection/2.png) | ![](https://github.com/CRekkaran/Smart-Filter/blob/master/Smile%20Detection/not%20smiling.png)\r\n\r\n## Smart Filters examples\r\n\r\nExample 1             |  Example 2\r\n:-------------------------:|:-------------------------:\r\n![](https://github.com/CRekkaran/Smart-Filter/blob/master/Semantic%20Segmentation/supportpride.png) | ![](https://github.com/CRekkaran/Smart-Filter/blob/master/Final%20Ensemble/index3_low_res.png)\r\n\r\nExample 1 is created by giving 'rainbow,texture' as parameters to background selection.\r\n> Insert code snippet.\r\n","note":"Don't delete this file! It's used internally to help with page regeneration."}